{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3dc4a882",
      "metadata": {
        "id": "3dc4a882"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e306f73c",
      "metadata": {
        "id": "e306f73c",
        "outputId": "b3a3f6be-29a7-4d9f-d575-496a081702ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3478b6eedd81>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRidgeCV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLassoCV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mElasticNetCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetaestimators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scorer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_check_multimetric_scoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_MultimetricScorer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFitFailedWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_classification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmultilabel_confusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_dist_metrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDistanceMetric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msklearn/metrics/_dist_metrics.pyx\u001b[0m in \u001b[0;36minit sklearn.metrics._dist_metrics\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
        "from sklearn.metrics import mean_squared_error, make_scorer\n",
        "from scipy.stats import skew\n",
        "from IPython.display import display\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd9273d6",
      "metadata": {
        "id": "fd9273d6"
      },
      "outputs": [],
      "source": [
        "#Seed고정함수(다 넣기)\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(42) # Seed 고정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "812aa648",
      "metadata": {
        "id": "812aa648"
      },
      "outputs": [],
      "source": [
        "train_df= pd.read_csv(r\"C:\\Users\\USER\\OneDrive - 한국외국어대학교\\바탕 화면\\2023 winter\\전력사용량 ai\\train.csv\")\n",
        "test_df= pd.read_csv(r\"C:\\Users\\USER\\OneDrive - 한국외국어대학교\\바탕 화면\\2023 winter\\전력사용량 ai\\test.csv\")\n",
        "building_df = pd.read_csv(r\"C:\\Users\\USER\\OneDrive - 한국외국어대학교\\바탕 화면\\2023 winter\\전력사용량 ai\\building_info.csv\")\n",
        "sample_df = pd.read_csv(r\"C:\\Users\\USER\\OneDrive - 한국외국어대학교\\바탕 화면\\2023 winter\\전력사용량 ai\\sample_submission.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "986cd10e",
      "metadata": {
        "id": "986cd10e"
      },
      "outputs": [],
      "source": [
        "#데이터 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2ee8134",
      "metadata": {
        "id": "e2ee8134"
      },
      "outputs": [],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d5f1b50",
      "metadata": {
        "id": "2d5f1b50"
      },
      "outputs": [],
      "source": [
        "test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6af04a9e",
      "metadata": {
        "id": "6af04a9e"
      },
      "outputs": [],
      "source": [
        "building_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65d743c5",
      "metadata": {
        "id": "65d743c5"
      },
      "outputs": [],
      "source": [
        "sample_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b72fdb52",
      "metadata": {
        "id": "b72fdb52"
      },
      "outputs": [],
      "source": [
        "#Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24bfc9ba",
      "metadata": {
        "id": "24bfc9ba"
      },
      "outputs": [],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d45402a3",
      "metadata": {
        "id": "d45402a3"
      },
      "outputs": [],
      "source": [
        "# 일조, 일사 열 제거\n",
        "train_df = train_df.drop(['일조(hr)','일사(MJ/m2)'], axis=1)\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a58b59d1",
      "metadata": {
        "id": "a58b59d1"
      },
      "outputs": [],
      "source": [
        "# 결측치 확인\n",
        "train_df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73ab2c75",
      "metadata": {
        "id": "73ab2c75"
      },
      "outputs": [],
      "source": [
        "# 강수량 결측치 0.0으로 채우기\n",
        "train_df['강수량(mm)'].fillna(0.0, inplace=True)\n",
        "\n",
        "# 풍속, 습도 결측치 평균으로 채우고 반올림하기\n",
        "train_df['풍속(m/s)'].fillna(round(train_df['풍속(m/s)'].mean(),2), inplace=True)\n",
        "train_df['습도(%)'].fillna(round(train_df['습도(%)'].mean(),2), inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4cc60b2",
      "metadata": {
        "id": "a4cc60b2"
      },
      "outputs": [],
      "source": [
        "train_df['month'] = train_df['일시'].apply(lambda x : float(x[4:6]))\n",
        "train_df['day'] = train_df['일시'].apply(lambda x : float(x[6:8]))\n",
        "train_df['time'] = train_df['일시'].apply(lambda x : float(x[9:11]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "225e2df0",
      "metadata": {
        "id": "225e2df0"
      },
      "outputs": [],
      "source": [
        "# 순서 재배치\n",
        "train_df = train_df[train_df.columns[:7].to_list() + train_df.columns[8:].to_list() + train_df.columns[7:8].to_list()]\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13797309",
      "metadata": {
        "id": "13797309"
      },
      "outputs": [],
      "source": [
        "# 하이퍼파라미터\n",
        "input_size = 8  # feature의 개수\n",
        "hidden_size = 64\n",
        "num_layers = 2\n",
        "output_size = 1\n",
        "num_epochs = 5\n",
        "window_size = 24  # 예측에 사용될 시간 윈도우 크기\n",
        "batch_size = 64\n",
        "learning_rate = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eed9870e",
      "metadata": {
        "id": "eed9870e"
      },
      "outputs": [],
      "source": [
        "#데이\n",
        "class TimeSeriesDataset(Dataset):\n",
        "    def __init__(self, df, window_size):\n",
        "        self.df = df\n",
        "        self.window_size = window_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df) - self.window_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.tensor(self.df[idx:idx+self.window_size, :], dtype=torch.float)\n",
        "        if self.df.shape[1] > 1:\n",
        "            y = torch.tensor(self.df[idx+self.window_size, -1], dtype=torch.float)\n",
        "        else:\n",
        "            y = None\n",
        "        return x, y\n",
        "\n",
        "def create_data_loader(df, window_size, batch_size):\n",
        "    dataset = TimeSeriesDataset(df, window_size)\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "    return data_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2667fcc",
      "metadata": {
        "id": "d2667fcc"
      },
      "outputs": [],
      "source": [
        "# normalization\n",
        "scaler = MinMaxScaler()\n",
        "train_data = scaler.fit_transform(train_df.drop(['num_date_time', '건물번호', '일시'], axis=1).values)\n",
        "train_loader = create_data_loader(train_data, window_size, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa47ddc5",
      "metadata": {
        "id": "fa47ddc5"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTM, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "151e2841",
      "metadata": {
        "id": "151e2841"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"current device: {device}\")\n",
        "\n",
        "model = LSTM(input_size, hidden_size, num_layers, output_size).to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b310f677",
      "metadata": {
        "id": "b310f677"
      },
      "outputs": [],
      "source": [
        "#Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a91dc61",
      "metadata": {
        "id": "2a91dc61"
      },
      "outputs": [],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.unsqueeze(1).to(device)\n",
        "\n",
        "        # Forward\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 300 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch+1, num_epochs, i+1, len(train_loader), loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6c34524",
      "metadata": {
        "id": "c6c34524"
      },
      "outputs": [],
      "source": [
        "# 학습 데이터에서 마지막 행 가져오기\n",
        "last_train_data = train_df.drop(['num_date_time', '건물번호', '일시',], axis=1).loc[204000-24:,:]\n",
        "\n",
        "# 실수형 데이터로 변환\n",
        "test_df['습도(%)'] = test_df['습도(%)'].astype('float64')\n",
        "\n",
        "# 날짜 데이터 추가\n",
        "test_df['month'] = test_df['일시'].apply(lambda x : float(x[4:6]))\n",
        "test_df['day'] = test_df['일시'].apply(lambda x : float(x[6:8]))\n",
        "test_df['time'] = test_df['일시'].apply(lambda x : float(x[9:11]))\n",
        "\n",
        "# 전력소비량 열 생성\n",
        "final_df = pd.concat((test_df.drop(['num_date_time', '건물번호', '일시',], axis=1), pd.DataFrame(np.zeros(test_df.shape[0]))),axis=1)\n",
        "final_df = final_df.rename({0:'전력소비량(kWh)'},axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc437fbd",
      "metadata": {
        "id": "bc437fbd"
      },
      "outputs": [],
      "source": [
        "test_df = pd.concat((last_train_data, final_df)).reset_index(drop=True)\n",
        "test_data = scaler.transform(test_df.values) # train과 동일하게 scaling\n",
        "test_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb29deb6",
      "metadata": {
        "id": "fb29deb6"
      },
      "outputs": [],
      "source": [
        "# Dataset & DataLoader\n",
        "test_dataset = TimeSeriesDataset(test_data, window_size)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59a826dd",
      "metadata": {
        "id": "59a826dd"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "test_predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(test_data.shape[0] - window_size):\n",
        "        x = torch.Tensor(test_data[i:i+window_size,:]).to(device)\n",
        "        new_x = model(x.view(1,window_size,-1))\n",
        "\n",
        "        test_data[i+window_size,-1] = new_x # 입력 업데이트\n",
        "        test_predictions.append(new_x.detach().cpu().numpy().item()) # 예측 결과 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1807cf00",
      "metadata": {
        "id": "1807cf00"
      },
      "outputs": [],
      "source": [
        "predictions = scaler.inverse_transform(test_data)[24:,-1] # 원래 scale로 복구"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06d5337a",
      "metadata": {
        "id": "06d5337a"
      },
      "outputs": [],
      "source": [
        "sample_df['answer'] = predictions\n",
        "sample_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0e72d2d",
      "metadata": {
        "id": "a0e72d2d"
      },
      "outputs": [],
      "source": [
        "sample_df.to_csv('lstm_baseline_submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a461419",
      "metadata": {
        "id": "6a461419"
      },
      "outputs": [],
      "source": [
        "#1. 데이터 확인 과정->\n",
        "#변수를 영어로 변경할 것인가?\n",
        "\n",
        "#2. 데이터 전처리 과정->\n",
        "\n",
        "#2-1) 결측치(trian_df)\n",
        "#결측치가 가장 많은 일조, 일사, 강수량 -> drop or fillna 0\n",
        "#그 다음의 결측치인 풍속과 습도의 결측치는? ->평균을 만들 것인가?\n",
        "\n",
        "#2-2) 이상치(train_df)\n",
        "\n",
        "#2-3) 로그변환\n",
        "\n",
        "#2-4) 변수 통합(공휴일+주말) & 임시휴무(drop?)\n",
        "\n",
        "#2-5) 시간변수 나누기 & 푸리에 변환 사용할 것인가?\n",
        "\n",
        "#2-6) 파생변수\n",
        "#일일평균기온, 일일최대기온, 일교차변수, 냉방도시, 불쾌지수, 체감온도 추가할 것인가?\n",
        "\n",
        "#2-7)피쳐 선택\n",
        "#종속변수: 전력소비량\n",
        "#독립변수(범주형 변수, 연속형 변수 분류)\n",
        "\n",
        "#3)모델\n",
        "#성과평과지표? kfold(몇 개로 나눌 것?), cross validation\n",
        "#사용 모델 XGBOOST\n",
        "#사용 하이퍼 파라미터? Max depth, subsample, colsample bytree, min child weight"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}